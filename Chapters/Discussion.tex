\fancyhf{}
\fancyhead[C]{Chapter 5. General Discussion}% <- added
\fancyfoot[R]{\thepage\ifodd\value{page}\else\hfill\fi}
%\fancyhead[L]{\ifodd\value{page}\relax\else\hfill\fi Ch \thechapter}
%\renewcommand\headrulewidth{0pt}% default ist .4pt
\renewcommand{\plainheadrulewidth}{.4pt}% default is 0pt


\section{Summary}

The broad aim of this thesis was to shed light on neuronal functional heterogeneity based on context and neuromodulation. The thesis addresses three questions: (1) Is neuronal identity context dependent, and which attributes best capture heterogeneity? (2) How does neuromodulation alter neuronal function? (3) How does intrinsic timescale heterogeneity influence network performance and memory? 

\textbf{Chapter 2} takes on the first research question. It challenges the long-standing assumption in systems neuroscience that neuronal functional identity is fixed. Through direct comparison of neuronal responses to different input regimes, I demonstrated that functional identity of neurons is context-dependent, varying with the nature of the input that neurons receive. Moreover, I provide a framework to compare the electrophysiological features commonly used in functional classification such as action potential dynamics and passive biophysical properties by exploiting the high dimensional functional feature space of neurons and comparing the feature sets and by showing that the linear input filter accounts for a greater proportion of variance across neurons. This makes it a more informative and discriminative feature for functional classification.

In \textbf{Chapter 3}, I took on the second research question. I show that neuromodulation alters information transfer in a cell-type and agonist-specific manner. While previous chapter established the role of input in functional classification and laid out a method to study and compare heterogeneity in high dimensional functional space extracted using a FN input, the influence of neuromodulation on this high-dimensional functional space was still not entirely understood. In this chapter I showed that these neuromodulatory changes in functional properties are not uniformly distributed across the neuronal population; instead, neuromodulation induces shifts in multiple functional properties in a coordinated manner, often making subpopulations more similar in their modulation based changes in functional properties. This adds further complexity to functional classification by showing that identity is not only input-dependent but also dynamically reshaped by internal network states.

Finally in \textbf{Chapter 4}, I extend the investigation of functional heterogeneity in neurons to artificial systems which attempts to answer the third research question. In this chapter I examine how intrinsic timescale heterogeneity affects performance in reservoir computing networks. I demonstrate that Echo State Networks (ESNs) and Distance-Dependent Delay Networks (DDNs) exhibit improved task performance and memory capacity when composed of units with heterogeneous time constants. This supports the idea that structured diversity enhances computational capability both in biological and artificial systems.          

By systematically investigating the research questions discussed above, I introduced a framework to study context based neuronal classification using single unit in-vitro patch clamp recordings. I established that neuronal functional identity depends on the input. I further provided a framework to compare neuronal functional heterogeneity based on four high dimensional attribute sets and show that linear input filter is the most informative feature for studying functional heterogeneity in single neurons. Furthermore, I showed that during a specific neuromodulatory receptor activation, single neurons alter their functional space in heterogeneous manner. Neuromodulation changes the information transfer capabilities of single neurons in a cell-type specific manner and most importantly, due to neuromodulation, the high-dimensional functional space is altered in coordination. Multiple-attribute sets are affected together rather than a single property. Synthesizing our findings from the data-driven investigation of single neurons, I studied the affect of intrinsic heterogeneity on artificial systems such as the reservoir computing systems. My investigation revealed that DDNs and ESNs improve their performance directly due to intrinsic timescale heterogeneity in individual units. I also show that heterogeneity benefits the performance of both ESNs and DDNs but in a task dependent manner. In the following sections I will discuss the broader implications of my findings and the future directions for this research. 


\section{Towards dynamic functional identity of single neurons}

\subsection{Input dependence challenges current taxonomies}

Most long standing efforts towards understanding neuronal heterogeneity have been standing on this assumption that neuronal functional identity is static (\cite{fishell2013neuron, huang2019diversity, markram2004interneurons, mukamel2019perspectives, nelson2006problem, petilla2008petilla, sanes2015types, seung2014neuronal, somogyi2005defined, yuste2020community, zeng2022cell, zeng2017neuronal,komendantov_quantitative_2019}). In \textbf{Chapter 2} I challenge this foundational assumption by showing that neuronal functional identity is context dependent. Despite large-scale classification efforts such as by the Allen Brain Institute (\cite{gouwens2019classification, gouwens2020integrated}), the dependence of electrophysiological types (e-types) on the nature of synaptic input remains largely overlooked. Currently, multi-modal classification efforts combine morphological, electrophysiological and transcriptomic markers together to define cell class. In these studies, a static step protocol is used to extract electrophysiological features. Our study challenges these classification results and demonstrates their input-dependence. Here, I provide evidence that neuronal classification is input-dependent, and that functional identity shifts under different stimulus regimes. This insight calls for a critical reassessment of current classification schemes such as by the Allen Institute (\cite{gouwens2019classification, gouwens2020integrated}) in systems neuroscience. These findings advocate for a paradigm shift: functional classification must be grounded in how neurons respond to realistic, time-varying inputs. Achieving this requires a renewed effort in data collection one that prioritizes dynamic stimulation paradigms. While more resource-intensive, this approach offers a deeper and more meaningful classification for modeling brain computation.


\subsection{Functional value of heterogeneity at the population Level}

In the previous section I described the role of dynamical functional identity in deciding functional classification, but this just one single aspect of the results in \textbf{Chapter 2}. The effect of dynamic functional identity of single neurons needs to be understood on broader scale, at the level of neural circuits. In this section, I aim to highlight the circuit level interpretation of functional heterogeneity. 

In\textbf{ Chapter 2}, STA emerged as uniquely informative for capturing population-level heterogeneity among the four attribute sets (AP, PB, AC and STA). This indicates that even within a single cortical region, the somatosensory cortex, neurons differ substantially in their linear input filters. Such diversity implies a level of functional modularity, where neurons are tuned to distinct input features. This specialization may provide a basis for modularity in cortical computation and aids cognitive flexibility (\cite{wu2025neural,hutt2023intrinsic}). Also, work by (\cite{buonomano2009state}) suggest that activity of a neuron in a network is a complex interaction of the network state at any given instant and the incoming stimuli. This view is completely supported by our finding, as such discarding fixed functional identity. It is likely that this heterogeneity would be even more pronounced when comparing neurons across different cortical areas. These findings argue that cortical models must incorporate variability in feature selectivity to accurately reflect population-level dynamics. 

Having established that STA reveals intrinsic functional heterogeneity, we next asked how this heterogeneity and functional classification can be reconfigured by neuromodulatory signals. In \textbf{Chapter 3}, I use the established framework to study neuromodulatory effects, focusing on dopaminergic (D1, D2) and cholinergic (muscarinic M1) receptor activation. Neuromodulation altered both the amount of information transmitted and the classification of neurons across the four attribute sets. I show that activation of specific receptors reshaped the correlation structure among these features, demonstrating that neuromodulation does not act on single properties in isolation but reorganizes the functional feature space of neurons. Notably, these effects were heterogeneous: subpopulations of neurons responded differently to each receptor agonist, indicating that neuromodulators can act as fine-tuned control mechanisms that selectively modulate specific subsets of the circuit \cite{ogawa2023multitasking,salvan2023serotonin,gast2024neural}. This suggests a dual role for neuromodulation both controlling baseline heterogeneity and exploiting it to regulate population-level dynamics in a context-sensitive manner.

There has been an extensive body of literature that discuss population level control via neuromodulation (\cite{Agnati1995,Fuxe2016,Herrington2016,CervantesSandoval2017,Little2013,Zilles2009,marder2014neuromodulation}). Neuromodulators work thorough volume transmission (\cite{Fuxe2016}), through which they control a group of neurons. Our results provide a direct evidence of this. We show a detailed view of the alteration of functional attributes in subgroups of neurons in the somatosensory cortex and the change in coordination between these functional attributes for a population. Together we show that neuronal identity is dynamic, altered by the input that individual neurons receive together with neuromodulation that altogether alters the network state in which a neuron is embedded by changing subgroups in a heterogeneous manner. Collectively, these findings challenge static taxonomies of cell types and argue for circuit models in which neuronal identity emerges dynamically from combined input and neuromodulatory context. 

\subsection{Introduction of Novel Analytical Methods to Study Functional Reorganization and High-Dimensional Correlations}

Addressing the dynamic nature of neuronal functional classification and heterogeneity required the application of analytical tools not traditionally used in electrophysiological studies. To this end, I employed unsupervised machine learning techniques specifically, Louvain clustering combined with UMAP for dimensionality reduction, and Multi-set Correlation and Factor Analysis (MCFA) (\cite{brown2023multiset}) for feature-space variance comparison.

While Louvain+UMAP has been previously applied to waveform clustering (\cite{lee2021non}), its application to electrophysiological feature spaces across distinct input contexts is novel. This method was useful for classifying high-dimensional attribute(s) extracted from the recordings due to its ability to exploit high-dimensional graph structure for clustering instead of a low dimensional projection which usually results in a loss of nuanced information. And also, due to the fact it is an unsupervised method with a robust hyperparameter selection criteria. In this thesis, I leveraged this framework to directly compare neuronal classifications under different stimulation regimes (e.g., step current vs. frozen noise), revealing context-dependent shifts in functional identity.

A persistent challenge in electrophysiological classification is the lack of consensus on which features most effectively capture neuronal heterogeneity. To move beyond arbitrary or limited feature selection, I employed MCFA to quantify the correlation structure across multiple high-dimensional attribute sets. This method allowed us to compare high dimensional attribute sets to identify the shared and private variance structure between the attribute sets. This allowed us to identify which sets are most informative for characterizing functional diversity. Furthermore, we used MCFA to assess how these correlation structures change under neuromodulatory influence, offering new insight into how functional properties reorganize in response to network state changes. 

Although UMAP+Louvain clustering and MCFA are established tools in genomics and single-cell omics (\cite{brown2023multiset}), their adoption in systems neuroscience remains limited. This thesis demonstrates their applicability to electrophysiological data and advocates for their broader use in analyzing the high-dimensional functional landscape of neurons. With more comprehensive datasets, these methods are likely to yield deeper, more robust insights into functional heterogeneity and neuronal classification. We also expect these methods to be adapted more widely for many other problem domains in neuroscience.

\section{Computational modeling implications}

I showed in \textbf{Chapter 2} and \textbf{Chapter 3} using single unit recordings that cortical neurons are heterogeneous in their functional properties and in the way they respond to neuromodulation. In \textbf{Chapter 4}, I tried to synthesize this observation in artificial system. In order to study the advantage it could have on computational properties of reservoir computing systems. 

\subsection{Heterogeneity Improves Reservoir Performance}

In \textbf{Chapter 4}, I demonstrate that timescale heterogeneity enhances the performance of both Echo State Networks (ESNs) and Distance-Dependent Delay Networks (DDNs) on NARMA-30 and Mackey-Glass tasks, particularly in terms of memory capacity and task accuracy. However, we found that the relationship is not monotonous: the most heterogeneous architecture, that is the DNN/ESN with heterogeneous cluster does not always yield the best results. Previous literature has supported structural heterogeneity in artificial networks, where modularity structure improves task performance (\cite{yang2024brain,manneschi2021exploiting}).   

DDNs already incorporate heterogeneous inter-unit delays by design (\cite{iacob2022distance}), which contributes to a more distributed memory profile compared to ESNs (\cite{iacob2022distance}). This structural feature gives DDNs a baseline advantage in tasks requiring temporal integration. Adding intrinsic decay (timescale) heterogeneity further enhances performance as shown in the memory capacity analysis but only up to a point. Beyond a certain level of heterogeneity, the gains diminish or reverse. This result proves the hypothesis by (\cite{tanaka2022reservoir}). This underscores a key insight: the benefits of timescale heterogeneity are task-dependent, and excessive heterogeneity can, in some cases, degrade performance. 

The benchmark tasks reinforce the need to define the optimal timescale heterogeneity, this has also been shown in previous literature to improve performance of spiking networks (\cite{mejias_optimal_2012,zheng2024temporal,tripathy_intermediate_2013,gjorgjieva2016computational,gjorgjieva_intrinsic_2014,duarte_leveraging_2019}). In the NARMA-30 task, which demands precise short-term memory, moderate timescale heterogeneity improved performance in both ESNs and DDNs. In contrast, for the Mackey-Glass task, a chaotic time-series prediction task, excessive heterogeneity introduced instability, reducing predictive accuracy. These results highlight the need to calibrate heterogeneity to the specific computational demands of the task. Various studies on spiking neural networks have demonstrated this task based heterogeneity (\cite{perez-nieves_neural_2021}). Also, intrinsic heterogeneity has been shown to improve encoding performance of spiking networks (\cite{chakraborty_heterogeneous_2022,zeldenrust_efficient_2021,gast2024neural,marsat2010neural}).  

Interestingly, both homogeneous cluster (clusters with singular decay value) and heterogeneous cluster (clusters with decay sampled from a distinct distribution) architectures outperformed fully homogeneous or fully heterogeneous networks across tasks. This suggests that structured heterogeneity variation organized into modular subgroups offers an optimal balance between flexibility (by diversifying time scales for memory) and control (by keeping the network dynamics contracting). This result connects well with the finding in \textbf{Chapter 2-3}, where I show that neuronal population has modularity in terms of modulation and in their intrinsic attributes. These findings emphasize that while intrinsic decay  heterogeneity is beneficial, its impact depends critically on its structure and distribution within the network.



% \subsection{Toward Architecture-Level Design Principles Grounded in Biology}

% \textbf{Chapters 2 and 3} reveal a fundamental insight into the extent and structure of heterogeneity in the somatosensory cortex. By extracting multiple facets of neuronal function including action potential dynamics, adaptation currents, and input selectivity I demonstrate that neurons within a single cortical region vary widely in how they process stimuli. This functional diversity contributes to the brain’s adaptability in responding to dynamic and unpredictable inputs.

% In \textbf{Chapter 4}, I abstracted this biological heterogeneity into artificial systems by implementing it within reservoir computing architectures. The results confirmed a core hypothesis: \textbf{heterogeneity at the unit level enhances the computational performance of interconnected systems}. These findings demonstrate that architectural principles rooted in observed biological phenomena can lead to more effective and flexible artificial systems.

% Moreover, the findings point to a second design insight: heterogeneity must be \textbf{task-aware}. As shown in the benchmark experiments, increasing diversity blindly can be counterproductive. Instead, architectural decisions should reflect both biological principles and task-specific constraints. In this context, “biologically inspired” design must not mean mimicking biology uncritically, but rather \textbf{translating its organizing logic} into systems that serve defined functional goals.

\subsection{Limitations and Methodological Constraints}

In this thesis I have used rigorous analysis and interpretation to show evidence against a static neuronal identity, effect of neuromodulation on neuronal functional space and effect of heterogeneity on the performance of reservoir computing networks. Even though the results are robust, it is important to acknowledge limitations pertaining to the methodology and data. 

First, while frozen noise stimulation provided a richer input space than the step and hold protocols, the overall number of cells recorded under each condition are limited. Consequently, the statistical power for detecting more subtle subpopulation-level effects. This also applies to the recordings for each agonist condition which is a subset of the original data. 

Second, while the classification results revealed clear context- and input-dependent changes in neuronal identity, these findings are currently restricted to neurons within the somatosensory cortex. It remains to be seen whether similar dynamic reconfigurations occur in other cortical or subcortical regions.

Third, the effects of neuromodulation were examined through pharmacological application of D1, D2, and M1 receptor agonists. While this approach isolated the contribution of each receptor type, it does not reflect the full complexity of in vivo neuromodulatory signaling, where multiple pathways act concurrently and interact with behavioral state.

Fourth, the MCFA method is linear in nature, the non-linear interactions between the attribute sets (AP, PB, AC, STA) are not captured by such a method. Therefore, the conclusion about co-regulations especially in case of neuromodulation should be interpreted with caution.  

Finally, in the computational modeling work, the performance of Echo State Networks (ESNs) and Distance-Dependent Delay Networks (DDNs) was benchmarked on a limited set of tasks. The generalizability of the observed heterogeneity and performance relationship to more complex architectures such as deep recurrent models, spiking neural networks, or biologically detailed simulations remains an open question.

While these limitations shape the scope of this study, they do not undermine its central contributions. The results related to heterogeneity remain robust, and the identified limitations instead point to concrete directions for further investigation in the direction of neuronal functional heterogeneity and networks. 

\subsection{Future Directions}

\subsubsection{Biological Extensions}

Future research should aim to extend electrophysiological recordings beyond step current protocols and further embrace dynamic, naturalistic stimulation regimes. One such recording protocol is Dynamic Clamp (\cite{robinson1993injection,sharp1993dynamic}). These would better approximate the range of inputs neurons experience in vivo and provide a richer substrate for functional classification. Additionally, integrating electrophysiology with other modalities such as transcriptomic profiling, morphological reconstruction, or in vivo imaging could yield a more comprehensive, multi-modal map of neuronal heterogeneity.

Another important direction is to link the observed functional reconfigurations induced by neuromodulation to behavior. There has been extensive body of work in this direction (\cite{Ott2023,Picciotto2012,Walters1987,Nadim2014,robinson2004firing}), which link the neuromodulation of single neurons by dopamine and acetylcholine to reward and learning. But comprehensive high-dimensional view of single neurons' functional space is missing. This potential area of research could involve combining neuromodulatory manipulation with behavioral paradigms and recording from populations in active animals, allowing us to trace how shifts in input filters or feature selectivity translate into changes in perception or motor output.

An important missing link in the context of our finding is the mechanistic explanation of heterogeneity found in linear input filters of the somatosensory neurons, a mechanistic understanding of how relatively homogeneous PB and AP properties give rise to heterogeneous input filters is required. Also, it is an interesting direction to study the effect of input filter heterogeneity in networks. There has been a large body of work such as by (\cite{marder_multiple_2011,marder2014neuromodulation,kumari2024ion, edelman_degeneracy_2001,hennig_constraints_2018}) identifying degeneracy in ion-channel activation and high-level functional properties such as the linear input filter and in a similar way, degeneracy in the activity of single neurons to produce network states. I suggest this direction to get a mechanistic understanding of homogeneity in AP and PB parameters giving rise to heterogeneous linear input filters. 

In Chapter 3 we found the emergence of subpopulations with heterogeneous modulation, it is interesting to pursue this idea on a circuit level to understand how such heterogeneous modulation dives rise to attention in case of dopamine and relate it to behavior in general. This would require a large scale data collection and modeling effort. 

In this thesis I have identified several potential research directions to pursue, which will enhance neuronal taxonomy and neuronal heterogeneity in general, understanding of neuromodulation on circuit level and lead towards mechanistic understanding of varying levels of heterogeneity among the four attribute sets.  

\subsubsection{Computational Extensions}

Besides the future research directions in neurobiology, there are many research direction to be pursued based on the computational part of this thesis. These research directions are aimed at synthesizing knowledge about neuronal heterogeneity and neuromodualtion and use it towards designing biologically inspire neural networks.         

On the modeling side, it will be important to investigate whether the benefits of structured heterogeneity extend to more powerful or biologically plausible architectures, such as spiking neural networks, long short-term memory (LSTM) networks, or transformer-based recurrent systems. A related question is whether heterogeneity should be hand-crafted, as done here, or learned through training a comparison that could provide insight into how diversity emerges through development or adaptation. 

Our network size in the current experiment is small compared to a cortical circuits, a larger network would yield a clearer understanding of the effect of intrinsic heterogeneity on networks. Especially their stability and memory. 

Evolutionary optimization or meta-learning approaches could be used to explore the space of possible heterogeneity structures. These tools may reveal principles for organizing diversity in artificial networks that generalize across tasks, paralleling the diversity we observe in biological circuits.

Finally, for our aim to understand biological underpinnings of heterogeneity in neuronal computation it is important to concern ourselves with biologically realistic networks such as spiking neural networks or cortical networks. Applying the observed heterogeneity in linear input filters and modularity in sub-populations on a network scale such as shown by \cite{liu2021cell} would provide much richer understanding of how these rather orthogonal facets of heterogeneity come together to affect computation.    


\section{Final Conclusion}

In this thesis I show that biologically realistic input is important for neuronal functional classification, moreover, neurons are distinguished by their linear input filter. Taking this idea further, I show that neuromodulators act as a secondary controller of neuronal function, altering information transfer by causing multi-dimensional change in neuronal functional space, I also find sub-population of neurons with distinct modulation profiles. This motivates for a network level study that leverages this sub-population heterogeneity to understand what effect it has on the overall computational properties of neurons. I found that reservoir computing networks benefit from subpopulation level heterogeneity. This showcases the importance of heterogeneity of individual unit. 

\subsection{Epilogue}

It is clear to me that neuronal diversity is not noise, rather a fundamental feature of the brain's architecture. This heterogeneity shapes the structure and function of neural circuits, giving rise to the complexity of behavior, and experience. Therefore, understanding neural diversity is essential not just for neuroscience, but for comprehending the variability that defines human societies. A deeper grasp of this functional diversity is not optional; it is necessary for understanding ourselves and the systems we build.


\newpage
\begin{spacing}{1.0} % Set the line spacing to single spacing
\fontsize{8pt}{8pt}\selectfont
\bibliographystyle{apalike}
\renewcommand{\bibname}{References}
\bibliography{All_bibtex}
\end{spacing}