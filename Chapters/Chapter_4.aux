\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {section}{Abstract}{148}{section*.97}\protected@file@percent }
\citation{koch1999complexity,habashy2024adapting}
\citation{london2010sensitivity,brunel2003firing,wang2020heterogeneity}
\citation{cavanagh2020diversity}
\citation{runyan2017distinct}
\citation{mcnaughton2006path}
\citation{hasson2008hierarchical,chu2020long}
\citation{lukovsevivcius2009reservoir}
\citation{jaeger2001echo}
\citation{schrauwen2007overview}
\citation{iacob2022distance}
\citation{izhikevich2006polychronization}
\citation{iacob2022distance,soriano2014delay,perez2021neural}
\@writefile{toc}{\contentsline {section}{Introduction}{149}{section*.98}\protected@file@percent }
\citation{london2010sensitivity,nam2017diversity,zhou2023temporal}
\citation{jaeger2001echo}
\citation{iacob2022distance}
\@writefile{toc}{\contentsline {section}{Methods}{152}{section*.99}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Network Design}{152}{subsection*.100}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Echo State networks }{152}{subsubsection*.101}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Distance based delay networks}{152}{subsubsection*.102}\protected@file@percent }
\citation{iacob2022distance}
\@writefile{toc}{\contentsline {subsection}{Task}{153}{subsection*.103}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{NARMA-30}{153}{subsubsection*.104}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Evaluation}{154}{subsubsection*.105}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Mackey-Glass}{154}{subsubsection*.106}\protected@file@percent }
\citation{hansen2006the-cma-evoluti}
\@writefile{toc}{\contentsline {subsubsection}{Evaluation}{155}{subsubsection*.107}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Training}{155}{subsection*.108}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{CMA-ES Optimization}{155}{subsubsection*.109}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Summary of the hyperparameters optimized by the CMA-ES algorithm for ESNs and DDNs, expressed as the number of clusters $K$ and spatial dimensions $D_s$.}}{156}{table.caption.110}\protected@file@percent }
\newlabel{tab:placeholder}{{4.1}{156}{Summary of the hyperparameters optimized by the CMA-ES algorithm for ESNs and DDNs, expressed as the number of clusters $K$ and spatial dimensions $D_s$}{table.caption.110}{}}
\@writefile{toc}{\contentsline {subsubsection}{Readout training}{156}{subsubsection*.111}\protected@file@percent }
\citation{boedecker2012information}
\citation{boedecker2012information}
\@writefile{toc}{\contentsline {subsection}{Lyapunov exponent}{157}{subsection*.112}\protected@file@percent }
\newlabel{eq:lyapuno}{{4.9}{157}{Lyapunov exponent}{equation.4.9}{}}
\citation{jordanou2023investigation}
\citation{jaeger2001short}
\@writefile{toc}{\contentsline {subsection}{Dimensionality}{158}{subsection*.113}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Linear Memory Capacity}{159}{subsection*.114}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Results}{160}{section*.115}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces \textbf  {Reservoir architecture and heterogeneity design in DDNs and ESNs:} \textbf  {(a)} DDNs were made heterogeneous by introducing heterogeniety in decay ($\mitalpha $), cluster heterogeneity is designed by sampling decays from different distributions for each cluster, similarly, network heterogeneity is designed by sampling decays from a single distribution. \textbf  {(b)} same heterogeneity designed for ESNs. }}{161}{figure.caption.116}\protected@file@percent }
\newlabel{fig:reservoir-arch}{{4.1}{161}{\textbf {Reservoir architecture and heterogeneity design in DDNs and ESNs:} \textbf {(a)} DDNs were made heterogeneous by introducing heterogeniety in decay ($\alpha $), cluster heterogeneity is designed by sampling decays from different distributions for each cluster, similarly, network heterogeneity is designed by sampling decays from a single distribution. \textbf {(b)} same heterogeneity designed for ESNs}{figure.caption.116}{}}
\@writefile{toc}{\contentsline {subsection}{Task Performance }{161}{subsection*.117}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{NARMA 30}{161}{subsubsection*.118}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Mackey-Glass}{162}{subsubsection*.119}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Stability and Dimensionality}{163}{subsection*.122}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Maximum Lyapunov Exponents}{163}{subsubsection*.123}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces \textbf  {Network performance for DDNs and ESNs with or without heterogeneity}: \textbf  {(a)} Line plot shows the perforamce in terms of NRMSE over generation during CMA-ES optimization for DDNs and ESNs during NARMA 30 task.}}{164}{figure.caption.120}\protected@file@percent }
\newlabel{fig:eval}{{4.2}{164}{\textbf {Network performance for DDNs and ESNs with or without heterogeneity}: \textbf {(a)} Line plot shows the perforamce in terms of NRMSE over generation during CMA-ES optimization for DDNs and ESNs during NARMA 30 task}{figure.caption.120}{}}
\@writefile{toc}{\contentsline {subsubsection}{Dimensionality}{167}{subsubsection*.124}\protected@file@percent }
\citation{jaeger2001short,jaeger2004harnessing}
\@writefile{toc}{\contentsline {subsection}{Linear Memory capacity}{168}{subsection*.127}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces \textbf  {Dynamics based on Lyapunov exponent and dimensionality of optimized networks:} \textbf  {(a-b)} shows the Lyapunov exponents of the optimized networks while performing the NARMA 30 (blue background) and Mackey-Glass (red background). \textbf  {(c-d)} shows the network dimensionality while performing the NARMA 30 (blue background) and Mackey-Glass timeseries prediction tasks (red background).}}{169}{figure.caption.125}\protected@file@percent }
\newlabel{fig:lyapunov}{{4.3}{169}{\textbf {Dynamics based on Lyapunov exponent and dimensionality of optimized networks:} \textbf {(a-b)} shows the Lyapunov exponents of the optimized networks while performing the NARMA 30 (blue background) and Mackey-Glass (red background). \textbf {(c-d)} shows the network dimensionality while performing the NARMA 30 (blue background) and Mackey-Glass timeseries prediction tasks (red background)}{figure.caption.125}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces \textbf  {Performance vs stability and Dimensionality} (\textbf  {a-b}) shows the maximum LE at the lowest perturbation magnitude (1e-9) vs maximum validation score for the most optimized networks while performing the NARMA 30 (blue background) and Mackey-Glass (red background). \textbf  {(c-d)} shows the network dimensionality vs maximum validation score reached while performing the NARMA 30 (blue background) and Mackey-Glass timeseries prediction tasks (red background).}}{170}{figure.caption.126}\protected@file@percent }
\newlabel{fig:lyapunov_vs_perf}{{4.4}{170}{\textbf {Performance vs stability and Dimensionality} (\textbf {a-b}) shows the maximum LE at the lowest perturbation magnitude (1e-9) vs maximum validation score for the most optimized networks while performing the NARMA 30 (blue background) and Mackey-Glass (red background). \textbf {(c-d)} shows the network dimensionality vs maximum validation score reached while performing the NARMA 30 (blue background) and Mackey-Glass timeseries prediction tasks (red background)}{figure.caption.126}{}}
\citation{iacob2022distance}
\citation{tanaka2022reservoir}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces \textbf  {Linear Memory Capacity of optimized networks}: \textbf  {(Left)} Linear memory capacity of the networks optimized for NARMA 30 task for different delays. \textbf  {(Right)} Linear memory capacity of the networks optimized for Mackey-Glass time series prediction task for different delays. }}{172}{figure.caption.128}\protected@file@percent }
\newlabel{fig:MC}{{4.5}{172}{\textbf {Linear Memory Capacity of optimized networks}: \textbf {(Left)} Linear memory capacity of the networks optimized for NARMA 30 task for different delays. \textbf {(Right)} Linear memory capacity of the networks optimized for Mackey-Glass time series prediction task for different delays}{figure.caption.128}{}}
\@writefile{toc}{\contentsline {section}{Discussion}{172}{section*.129}\protected@file@percent }
\citation{Lundqvist2016gamma,Runyan2017timescales,Cavanagh2020diverse}
\citation{gao2015simplicity}
\citation{gast2024neural}
\bibstyle{apalike}
\bibdata{All_bibtex}
\bibcite{boedecker2012information}{{1}{2012}{{Boedecker et~al.}}{{}}}
\bibcite{brunel2003firing}{{2}{2003}{{Brunel and Wang}}{{}}}
\bibcite{Cavanagh2020diverse}{{3}{2022}{{Cavanagh et~al.}}{{}}}
\bibcite{cavanagh2020diversity}{{4}{2020}{{Cavanagh et~al.}}{{}}}
\bibcite{chu2020long}{{5}{2020}{{Chu et~al.}}{{}}}
\bibcite{habashy2024adapting}{{6}{2024}{{Habashy et~al.}}{{}}}
\bibcite{hansen2006the-cma-evoluti}{{7}{2006}{{Hansen et~al.}}{{}}}
\bibcite{hasson2008hierarchical}{{8}{2008}{{Hasson et~al.}}{{}}}
\bibcite{iacob2022distance}{{9}{2022}{{Iacob et~al.}}{{}}}
\bibcite{izhikevich2006polychronization}{{10}{2006}{{Izhikevich}}{{}}}
\bibcite{jaeger2001short}{{11}{2001a}{{Jaeger}}{{}}}
\bibcite{jaeger2001echo}{{12}{2001b}{{Jaeger}}{{}}}
\bibcite{koch1999complexity}{{13}{1999}{{Koch and Laurent}}{{}}}
\bibcite{london2010sensitivity}{{14}{2010}{{London et~al.}}{{}}}
\bibcite{lukovsevivcius2009reservoir}{{15}{2009}{{Lukoševičius and Jaeger}}{{}}}
\bibcite{Lundqvist2016gamma}{{16}{2016}{{Lundqvist et~al.}}{{}}}
\bibcite{mcnaughton2006path}{{17}{2006}{{McNaughton et~al.}}{{}}}
\bibcite{nam2017diversity}{{18}{2017}{{Nam et~al.}}{{}}}
\bibcite{Runyan2017timescales}{{19}{2017a}{{Runyan et~al.}}{{}}}
\bibcite{runyan2017distinct}{{20}{2017b}{{Runyan et~al.}}{{}}}
\bibcite{schrauwen2007overview}{{21}{2007}{{Schrauwen et~al.}}{{}}}
\bibcite{soriano2014delay}{{22}{2014}{{Soriano et~al.}}{{}}}
\bibcite{tanaka2022reservoir}{{23}{2022}{{Tanaka et~al.}}{{}}}
\bibcite{wang2020heterogeneity}{{24}{2020}{{Wang et~al.}}{{}}}
\bibcite{zhou2023temporal}{{25}{2023}{{Zhou et~al.}}{{}}}
\@setckpt{Chapters/Chapter_4}{
\setcounter{page}{179}
\setcounter{equation}{13}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{0}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{5}
\setcounter{table}{1}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{NAT@ctr}{25}
\setcounter{blindtext}{1}
\setcounter{Blindtext}{5}
\setcounter{blind@countparstart}{0}
\setcounter{blindlist}{0}
\setcounter{blindlistlevel}{0}
\setcounter{blindlist@level}{0}
\setcounter{blind@listcount}{0}
\setcounter{blind@levelcount}{0}
\setcounter{blind@randomcount}{0}
\setcounter{blind@randommax}{0}
\setcounter{blind@pangramcount}{0}
\setcounter{blind@pangrammax}{0}
\setcounter{KVtest}{0}
\setcounter{parentequation}{0}
\setcounter{nlinenum}{0}
\setcounter{float@type}{4}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{tblrcount}{0}
\setcounter{r@tfl@t}{0}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{section@level}{0}
\setcounter{Item}{18}
\setcounter{Hfootnote}{0}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{27}
}
